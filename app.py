import os
import concurrent.futures
from dotenv import load_dotenv
from openai import OpenAI
from flask import Flask, request, render_template, jsonify


load_dotenv()

app = Flask(__name__)

# prompt to run through OpenAI
promptBuilder = [
    """
    I am having trouble on deciding an outfit and would like you to
    help me by providing some insight and examples of outfits that would
    suit my preferences.
    """
]

# tracker for currently showing question
promptIndex = 0

"""
Question is given to the user to answer. The answer is then taken
and inserted into the "formula" and appeneded to promptBuilder. The answer
is also displayed on the webpage via highlight.
"""

promptQuestions = [
    {
        "question": "What is your gender?",
        "highlight": "Sex",
        "formula": "I am a {{0}}."
    },
    {
        "question": "What fashion style are you interested in?",
        "highlight": "Fashion Style",
        "formula": "I am interested in {{0}} fashion style."
    },
    {
        "question": "What is the weather at the moment?",
        "highlight": "Weather",
        "formula": "The weather is {{0}}."
    },
    {
        "question": "Is there any color you are trying to incorporate?",
        "highlight": "Color",
        "formula": "I would like to incorporate some {{0}} into my outfit."
    },
]

# the highlights displayed on the webpage
inputDecisions = ["Outfit Generator"]

# outfits generated by openai/dall-e
# [{ outfit: ['', ...], url: '' }, ...]
outputData = []

# tracker for currently showing outfit
outputIndex = 0

client = OpenAI(api_key=os.environ.get("OPENAI_USER_API_KEY"))


@app.route("/")
def home_page():
    initialQuestion = promptQuestions[promptIndex]['question']

    return render_template("home.html", inputDecisions=inputDecisions, promptQuestion=initialQuestion)


@app.route("/gather")
def append_prompt_query():
    global promptIndex, promptBuilder

    promptQuestion = promptQuestions[promptIndex]
    promptResponse = request.args.get("promptResponse")

    inputDecisions.append(f"{promptQuestion['highlight']}: {promptResponse}")

    # append user-answer-based prompt to promptBuilder
    promptBuilder.append(
        promptQuestion['formula'].replace("{{0}}", promptResponse))
    promptIndex += 1

    # if more questions need to be answered, update question tracker index
    if promptIndex < len(promptQuestions):
        nextQuestion = promptQuestions[promptIndex]['question']
    else:
        nextQuestion = None
        promptIndex = 0

    return render_template("home.html", inputDecisions=inputDecisions, promptQuestion=nextQuestion)


# send formulated prompt to openai/dall-e to receive text/image response
@app.route("/simulate")
def post_prompt_response():
    # explain the format the response should be given in
    #
    # Outfit 1:
    # - Black oversized hoodie
    # - High-waisted..
    # - ..
    # - ..
    # - ..
    promptBuilder.append(
        """
        Can you list 5 different outfits that revolve around my preferences? I want
        the output to be in this format:\n\n
        Outfit 1:\n- Black oversized hoodie\n- High-waisted black jeans\n- Black beanie\n
        - Black combat boots\n- Oversized plaid scarf in black and white
        """
    )

    # generated outfits
    outfits = []
    # generated apparel per outfit
    current_outfit = []

    # text response
    completion_content = generate_chat(promptBuilder)
    lines = completion_content.split('\n')

    for line in lines:
        if line.startswith("Outfit"):
            # start of new outfit
            if current_outfit:
                outfits.append(current_outfit)
                current_outfit = []
        elif line.startswith('-'):
            current_outfit.append(line.replace('-', '').strip())

    if current_outfit:
        outfits.append(current_outfit)

    # image response (url)
    images = generate_images(outfits)

    # combine text/image results into one stream
    for i in range(len(outfits)):
        outputData.append({
            'outfit': outfits[i],
            'url': images[i]
        })

    return render_template("generated.html", inputDecisions=inputDecisions, outfitNumber=outputIndex, outfit=outputData[outputIndex]['outfit'], url=outputData[outputIndex]['url'])


# return next generated outfit
@app.route("/simulate_next")
def prompt_next_response():
    global outputIndex

    if outputIndex < len(outputData) - 1:
        outputIndex += 1

    return render_template("generated.html", inputDecisions=inputDecisions, outfitNumber=outputIndex, outfit=outputData[outputIndex]['outfit'], url=outputData[outputIndex]['url'])


# return previous generated outfit
@app.route("/simulate_prev")
def prompt_prev_response():
    global outputIndex

    if outputIndex > 0:
        outputIndex -= 1

    return render_template("generated.html", inputDecisions=inputDecisions, outfitNumber=outputIndex, outfit=outputData[outputIndex]['outfit'], url=outputData[outputIndex]['url'])


# reset page/data
@app.route("/reset")
def reset_prompt():
    global promptIndex, promptBuilder

    promptBuilder = promptBuilder[0:]
    promptIndex = 0

    initialQuestion = promptQuestions[0]['question']

    return render_template("home.html", inputDecisions=inputDecisions, promptQuestion=initialQuestion)


def generate_chat(promptBuilder):
    # generate response from openai
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "user",
                "content": message
            } for message in promptBuilder
        ]
    )

    return completion.choices[0].message.content


def generate_images(outfits):
    # generated images
    # temporarily changed to static images because of api cost
    images = [
        "https://wallpapercave.com/wp/wp4471355.jpg",
        "https://wallpapercave.com/wp/wp4471360.jpg",
        "https://wallpapercave.com/wp/wp4471363.jpg",
        "https://wallpapercave.com/wp/wp4471366.jpg",
        "https://wallpapercave.com/wp/wp4471373.jpg"
    ]

    # generate images from dall-e
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(outfits)) as executor:
        futures = [executor.submit(generate_image, outfit) for outfit in outfits]
        
        results = [future.result() for future in concurrent.futures.as_completed(futures)]

    images = [image.data[0].url for image in results]

    return images


def generate_image(outfit):
    clothes = ", ".join([apparel for apparel in outfit])
    prompt = f"{promptBuilder[1]} I am wearing {clothes}."
    
    response = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size="1024x1024",
        quality="hd",
        n=1
    )
    
    return response


if __name__ == "__main__":
    app.run(debug=True)
