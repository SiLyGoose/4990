import os
from dotenv import load_dotenv
from openai import OpenAI
from flask import Flask, request, render_template, jsonify


load_dotenv()

app = Flask(__name__)

# prompt to run through OpenAI
promptBuilder = [
    """
    I am having trouble on deciding an outfit and would like you to
    help me by providing some insight and examples of outfits that would
    suit my preferences.
    """
]

# tracker for currently showing question
promptIndex = 0

"""
Question is given to the user to answer. The answer is then taken
and inserted into the "formula" and appeneded to promptBuilder. The answer
is also displayed on the webpage via highlight.
"""
promptQuestions = [
    {
        "question": "What is your gender?",
        "highlight": "Sex",
        "formula": "I am a {{0}}."
    },
    {
        "question": "What fashion style are you interested in?",
        "highlight": "Fashion Style",
        "formula": "I am interested in {{0}} fashion style."
    },
    {
        "question": "What is the weather at the moment?",
        "highlight": "Weather",
        "formula": "The weather is {{0}}."
    },
    {
        "question": "Is there any color you are trying to incorporate?",
        "highlight": "Color",
        "formula": "I would like to incorporate some {{0}} into my outfit."
    },
]

# the highlights displayed on the webpage
inputDecisions = ["LymonAI"]

# outfits generated by openai/dall-e
# [{ outfit: ['', ...], url: '' }, ...]
outputData = []

# tracker for currently showing outfit
outputIndex = 0


@app.route("/")
def home_page():
    initialQuestion = promptQuestions[promptIndex]['question']

    return render_template("home.html", inputDecisions=inputDecisions, promptQuestion=initialQuestion)


client = OpenAI(api_key=os.environ.get("OPENAI_USER_API_KEY"))

"""
ChatCompletion(
    id='chatcmpl-9GGAnnyMvlWYjCGwS9O2KU4vV37Yd',
    choices=[Choice(finish_reason='stop',
                    index=0,
                    logprobs=None,
                    message=ChatCompletionMessage(content='Prompt engineering involves designing and developing prompts that guide users through a process or task in a way that is effective, efficient, and user-friendly. Prompts are messages or cues that appear on a user interface to prompt the user to perform a specific action or provide specific information. \n\nPrompt engineering can involve designing prompts that are clear, concise, and easy to understand, as well as ensuring that prompts are displayed at the right time and in the right context to be most helpful to the user. By carefully designing and implementing prompts, engineers can help users navigate complex systems or tasks more easily and effectively, leading to a better user experience overall.',
                    role='assistant',
                    function_call=None,
                    tool_calls=None))
            ],
            created=1713662445,
            model='gpt-3.5-turbo-0125',
            object='chat.completion',
            system_fingerprint='fp_c2295e73ad',
            usage=CompletionUsage(completion_tokens=126,
                                  prompt_tokens=14, total_tokens=140)
)
"""
@app.route("/gather")
def append_prompt_query():
    global promptIndex, promptBuilder

    promptQuestion = promptQuestions[promptIndex]
    promptResponse = request.args.get("promptResponse")

    inputDecisions.append(f"{promptQuestion['highlight']}: {promptResponse}")

    # append user-answer-based prompt to promptBuilder
    promptBuilder.append(
        promptQuestion['formula'].replace("{{0}}", promptResponse))
    promptIndex += 1

    # if more questions need to be answered, update question tracker index
    if promptIndex < len(promptQuestions):
        nextQuestion = promptQuestions[promptIndex]['question']
    else:
        nextQuestion = None
        promptIndex = 0

    return render_template("home.html", inputDecisions=inputDecisions, promptQuestion=nextQuestion)


# send formulated prompt to openai/dall-e to receive text/image response
@app.route("/simulate")
def post_prompt_response():
    # explain the format the response should be given in
    # 
    # Outfit 1:
    # - Black oversized hoodie
    # - High-waisted..
    # - ..
    # - ..
    # - ..
    promptBuilder.append(
        """
        Can you list 5 different outfits that revolve around my preferences? I want
        the output to be in this format:\n\n
        Outfit 1:\n- Black oversized hoodie\n- High-waisted black jeans\n- Black beanie\n
        - Black combat boots\n- Oversized plaid scarf in black and white
        """
    )

    # generate response from openai
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "user",
                "content": message
            } for message in promptBuilder
        ]
    )

    # generated outfits
    outfits = []
    # generated apparel per outfit
    current_outfit = []
    
    # text response
    completion_content = completion.choices[0].message.content
    lines = completion_content.split('\n')

    for line in lines:
        if line.startswith("Outfit"):
            # start of new outfit
            if current_outfit:
                outfits.append(current_outfit)
                current_outfit = []
        elif line.startswith('-'):
            current_outfit.append(line.replace('-', '').strip())

    if current_outfit:
        outfits.append(current_outfit)

    # generated images
    # temporarily changed to static images because of api cost
    images = [
        "https://wallpapercave.com/wp/wp4471355.jpg",
        "https://wallpapercave.com/wp/wp4471360.jpg",
        "https://wallpapercave.com/wp/wp4471363.jpg",
        "https://wallpapercave.com/wp/wp4471366.jpg",
        "https://wallpapercave.com/wp/wp4471373.jpg"
    ]

    # generate images from dall-e
    # for outfit in outfits:
    #     clothes = ", ".join([clothing for clothing in outfit])
    #     image_prompt = f"{promptBuilder[1]} I am wearing {clothes}."

    #     response = client.images.generate(
    #         model="dall-e-3",
    #         prompt=image_prompt,
    #         size="1024x1024",
    #         quality="hd",
    #         n=1
    #     )

    #     images.append(response.data[0].url)

    # combine text/image results into one stream
    for i in range(len(outfits)):
        outputData.append({
            'outfit': outfits[i],
            'url': images[i]
        })

    return render_template("generated.html", inputDecisions=inputDecisions, outfitNumber=outputIndex, outfit=outputData[outputIndex]['outfit'], url=outputData[outputIndex]['url'])


# return next generated outfit
@app.route("/simulate_next")
def prompt_next_response():
    global outputIndex

    if outputIndex < len(outputData) - 1:
        outputIndex += 1

    return render_template("generated.html", inputDecisions=inputDecisions, outfitNumber=outputIndex, outfit=outputData[outputIndex]['outfit'], url=outputData[outputIndex]['url'])


# return previous generated outfit
@app.route("/simulate_prev")
def prompt_prev_response():
    global outputIndex

    if outputIndex > 0:
        outputIndex -= 1

    return render_template("generated.html", inputDecisions=inputDecisions, outfitNumber=outputIndex, outfit=outputData[outputIndex]['outfit'], url=outputData[outputIndex]['url'])


# reset page/data
@app.route("/reset")
def reset_prompt():
    global promptIndex, promptBuilder

    promptBuilder = promptBuilder[0:]
    promptIndex = 0

    initialQuestion = promptQuestions[0]['question']

    return render_template("home.html", inputDecisions=inputDecisions, promptQuestion=initialQuestion)


if __name__ == "__main__":
    app.run(debug=True)
